# -*- coding: utf-8 -*-
"""FewShot_GatedConvVAE_OrthoSylvesterVAE_WGAN_RandomNoise - Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ILCEXEQ1iXATSVJGGqGEWr5Qsm9RDkzr
"""

#!pip install tensorboardX

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import os
from PIL import Image

from torch.utils.data import Dataset
import torch
import torchvision.datasets as datasets
import torchvision.transforms as transforms

import random
import pickle as pkl
import numpy as np

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class MnistMetaEnv:
    def __init__(self, height=28, length=28):
        self.channels = 1
        self.height = height
        self.length = length
        self.data = datasets.MNIST(root='./data', train=True, download=True)
        self.make_tasks()
        self.split_validation_and_training_task()
        self.to_tensor = transforms.ToTensor()
        self.resize = transforms.Resize((self.height, self.length))
        self.sample_training_task()
    
    def sample_training_task(self, batch_size=64):
        task = str(random.sample(self.training_task, 1)[0])
        task_idx = random.sample(self.task_to_examples[task], batch_size)

        batch = torch.tensor(np.array([self.to_tensor(self.resize(self.data[idx][0])).numpy() for idx in task_idx]), dtype=torch.float, device=device)
        return batch, task
    
    def sample_validation_task(self, batch_size=64):
        task = str(random.sample(self.validation_task, 1)[0])
        task_idx = random.sample(self.task_to_examples[task], batch_size)

        batch = torch.tensor(np.array([self.to_tensor(self.resize(self.data[idx][0])).numpy() for idx in task_idx]), dtype=torch.float, device=device)
        return batch, task

    def make_tasks(self):
        self.task_to_examples = {}
        self.all_tasks = set(self.data.targets.numpy())
        for i, digit in enumerate(self.data.targets.numpy()):
            if str(digit) not in self.task_to_examples:
                self.task_to_examples[str(digit)] = []
            self.task_to_examples[str(digit)].append(i)

    def split_validation_and_training_task(self):
        self.validation_task = {9}
        self.training_task = self.all_tasks - self.validation_task


class OmniglotMetaEnv:
    def __init__(self, height=32, length=32):
        self.channels = 1
        self.height = height
        self.length = length
        self.data = datasets.Omniglot(root='./data', download=True)
        self.make_tasks()
        self.split_validation_and_training_task()
        self.resize = transforms.Resize((self.height, self.length))
        self.to_tensor = transforms.ToTensor()
    
    def sample_training_task(self, batch_size=4):
        task = str(random.sample(self.training_task, 1)[0])
        task_idx = random.sample(self.task_to_examples[task], batch_size)

        batch = torch.tensor(np.array([self.to_tensor(self.resize(self.data[idx][0])).numpy() for idx in task_idx]), dtype=torch.float, device=device)
        return batch, task
    
    def sample_validation_task(self, batch_size=64):
        task = str(random.sample(self.validation_task, 1)[0])
        task_idx = random.sample(self.task_to_examples[task], batch_size)

        batch = torch.tensor(np.array([self.to_tensor(self.resize(self.data[idx][0])).numpy() for idx in task_dix]), dtype=torch.float, device=device)
        return batch, task

    def make_tasks(self):
        self.task_to_examples = {}
        self.all_tasks = set()
        for i, (_, digit) in enumerate(self.data):
            self.all_tasks.update([digit])
            if str(digit) not in self.task_to_examples:
                self.task_to_examples[str(digit)] = []
            self.task_to_examples[str(digit)].append(i)

    def split_validation_and_training_task(self):
        self.validation_task = set(random.sample(self.all_tasks, 20))
        self.training_task = self.all_tasks - self.validation_task


class FIGR8MetaEnv(Dataset):
    def __init__(self, height=32, length=32):
        self.channels = 1
        self.height = height
        self.length = length
        self.resize = transforms.Resize((height, length))
        self.to_tensor = transforms.ToTensor()

        self.tasks = self.get_tasks()
        self.all_taks = set(self.tasks)
        self.split_validation_and_training_task()
    
    def get_tasks(self):
        if os.path.exists('./data/FIGR-8') is False:
            if os.path.exists('./data') is False:
                os.mkdir('./data')
            os.mkdir('./data/FIGR-8')
            from google_drive_downloader import GoogleDriveDownloader as gdd
            gdd.download_file_from_google_drive(file_id='10dF30Qqi9RdIUmET9fBhyeRN0hJmq7pO', dest_path='./data/FIGR-8/Data.zip')

            import zipfile
            with zipfile.ZipFile('./data/FIGR-8/Data.zip', 'r') as zip_f:
                zip_f.extractall('./data/FIGR-8/')
            os.remove('./data/FIGR-8/Data.zip')
        
        tasks = dict()
        path = './data/FIGR-8/Data'
        for task in os.listdir(path):
            tasks[task] = []
            task_path = os.path.join(path, task)
            for imgs in os.listdir(task_path):
                img = Image.open(os.path.join(task_path, imgs))
                tasks[task].append(np.array(self.to_tensor(self.resize(img))))
            tasks[task] = np.array(tasks[task])
        return tasks
    
    def split_validation_and_training_task(self):
        self.validation_task = set(random.sample(self.all_tasks, 50))
        self.training_task = self.all_tasks - self.validation_task
        pkl.dump(self.validation_task, open('validation_task.pkl', 'wb'))
        pkl.dump(self.training_task, open('training_task.pkl', 'wb'))
    
    def sample_training_task(self, batch_size=4):
        task = random.sample(self.training_task, 1)[0]
        task_idx = random.sample([i for i in range(self.tasks[task].shape[0])], batch_size)
        batch = self.tasks[task][task_idx]
        batch = torch.tensor(batch, dtype=torch.float, device=device)
        return batch, task
    
    def sample_validation_task(self, batch_size=4):
        task = random.sample(self.validation_task, 1)[0]
        task_idx = random.sample([i for i in range(self.tasks[task].shape[0])], batch_size)
        batch = self.tasks[task][task_idx]
        batch = torch.tensor(batch, dtype=torch.float, device=device)
        return batch, task
    
    def __len__(self):
        return len(self.files)

import torch
import torch.nn as nn
import numpy as np
import torch.nn.functional as F

class GatedConv2d(nn.Module):
    def __init__(self, input_channels, output_channels, kernel_size, stride, padding, dilation=1, activation=None):
        super(GatedConv2d, self).__init__()

        self.activation = activation
        self.sigmoid = nn.Sigmoid()

        self.h = nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding, dilation)
        self.g = nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding, dilation)

    def forward(self, x):
        if self.activation is None:
            h = self.h(x)
        else:
            h = self.activation(self.h(x))

        g = self.sigmoid(self.g(x))

        return h * g


class GatedConvTranspose2d(nn.Module):
    def __init__(self, input_channels, output_channels, kernel_size, stride, padding, output_padding=0, dilation=1,
                 activation=None):
        super(GatedConvTranspose2d, self).__init__()

        self.activation = activation
        self.sigmoid = nn.Sigmoid()

        self.h = nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding, output_padding,
                                    dilation=dilation)
        self.g = nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding, output_padding,
                                    dilation=dilation)

    def forward(self, x):
        if self.activation is None:
            h = self.h(x)
        else:
            h = self.activation(self.h(x))

        g = self.sigmoid(self.g(x))

        return h * g

from torch.autograd import Variable

def initialize_weights(net):
    for m in net.modules():
        if isinstance(m, nn.Conv2d):
            m.weight.data.normal_(0, 0.02)
            m.bias.data.zero_()
        elif isinstance(m, nn.ConvTranspose2d):
            m.weight.data.normal_(0, 0.02)
            m.bias.data.zero_
        elif isinstance(m, nn.Linear):
            m.weight.data.normal_(0, 0.02)
            m.bias.data.zero_()

class VAE(nn.Module):
    """
    The base VAE class containing gated convolutional encoder and decoder architecture.
    Can be used as a base class for VAE's with normalizing flows.
    """

    def __init__(self, input_size, input_type, z_size, device):
        super(VAE, self).__init__()

        # extract model settings from args
        self.z_size = z_size
        self.input_size = input_size
        self.input_type = input_type

        if self.input_size == [1, 28, 28] or self.input_size == [3, 28, 28]:
            self.last_kernel_size = 7
        elif self.input_size == [1, 28, 20]:
            self.last_kernel_size = (7, 5)
        else:
            raise ValueError('invalid input size!!')

        self.q_z_nn, self.q_z_mean, self.q_z_var = self.create_encoder()
        self.p_x_nn, self.p_x_mean = self.create_decoder()

        self.q_z_nn_output_dim = 256

        # auxiliary
        if device == 'cuda':
            self.FloatTensor = torch.cuda.FloatTensor
        else:
            self.FloatTensor = torch.FloatTensor

        # log-det-jacobian = 0 without flows
        self.log_det_j = Variable(self.FloatTensor(1).zero_())

    def create_encoder(self):
        """
        Helper function to create the elemental blocks for the encoder. Creates a gated convnet encoder.
        the encoder expects data as input of shape (batch_size, num_channels, width, height).
        """

        if self.input_type == 'binary':
            q_z_nn = nn.Sequential(
                GatedConv2d(self.input_size[0], 32, 5, 1, 2),
                GatedConv2d(32, 32, 5, 2, 2),
                GatedConv2d(32, 64, 5, 1, 2),
                GatedConv2d(64, 64, 5, 2, 2),
                GatedConv2d(64, 64, 5, 1, 2),
                GatedConv2d(64, 256, self.last_kernel_size, 1, 0),

            )
            q_z_mean = nn.Linear(256, self.z_size)
            q_z_var = nn.Sequential(
                nn.Linear(256, self.z_size),
                nn.Softplus(),
            )
            return q_z_nn, q_z_mean, q_z_var

        elif self.input_type == 'multinomial':
            act = None

            q_z_nn = nn.Sequential(
                GatedConv2d(self.input_size[0], 32, 5, 1, 2, activation=act),
                GatedConv2d(32, 32, 5, 2, 2, activation=act),
                GatedConv2d(32, 64, 5, 1, 2, activation=act),
                GatedConv2d(64, 64, 5, 2, 2, activation=act),
                GatedConv2d(64, 64, 5, 1, 2, activation=act),
                GatedConv2d(64, 256, self.last_kernel_size, 1, 0, activation=act)
            )
            q_z_mean = nn.Linear(256, self.z_size)
            q_z_var = nn.Sequential(
                nn.Linear(256, self.z_size),
                nn.Softplus(),
                nn.Hardtanh(min_val=0.01, max_val=7.)

            )
            return q_z_nn, q_z_mean, q_z_var

    def create_decoder(self):
        """
        Helper function to create the elemental blocks for the decoder. Creates a gated convnet decoder.
        """

        num_classes = 256

        if self.input_type == 'binary':
            p_x_nn = nn.Sequential(
                GatedConvTranspose2d(self.z_size, 64, self.last_kernel_size, 1, 0),
                GatedConvTranspose2d(64, 64, 5, 1, 2),
                GatedConvTranspose2d(64, 32, 5, 2, 2, 1),
                GatedConvTranspose2d(32, 32, 5, 1, 2),
                GatedConvTranspose2d(32, 32, 5, 2, 2, 1),
                GatedConvTranspose2d(32, 32, 5, 1, 2)
            )

            p_x_mean = nn.Sequential(
                nn.Conv2d(32, self.input_size[0], 1, 1, 0),
                nn.Sigmoid()
            )
            return p_x_nn, p_x_mean

        elif self.input_type == 'multinomial':
            act = None
            p_x_nn = nn.Sequential(
                GatedConvTranspose2d(self.z_size, 64, self.last_kernel_size, 1, 0, activation=act),
                GatedConvTranspose2d(64, 64, 5, 1, 2, activation=act),
                GatedConvTranspose2d(64, 32, 5, 2, 2, 1, activation=act),
                GatedConvTranspose2d(32, 32, 5, 1, 2, activation=act),
                GatedConvTranspose2d(32, 32, 5, 2, 2, 1, activation=act),
                GatedConvTranspose2d(32, 32, 5, 1, 2, activation=act)
            )

            p_x_mean = nn.Sequential(
                nn.Conv2d(32, 256, 5, 1, 2),
                nn.Conv2d(256, self.input_size[0] * num_classes, 1, 1, 0),
                # output shape: batch_size, num_channels * num_classes, pixel_width, pixel_height
            )

            return p_x_nn, p_x_mean

        else:
            raise ValueError('invalid input type!!')

    def reparameterize(self, mu, var):
        """
        Samples z from a multivariate Gaussian with diagonal covariance matrix using the
         reparameterization trick.
        """

        std = var.sqrt()
        eps = self.FloatTensor(std.size()).normal_()
        eps = Variable(eps).to(device)
        z = eps.mul(std).add_(mu)

        return z

    def encode(self, x):
        """
        Encoder expects following data shapes as input: shape = (batch_size, num_channels, width, height)
        """

        h = self.q_z_nn(x)
        h = h.view(h.size(0), -1)
        mean = self.q_z_mean(h)
        var = self.q_z_var(h)

        return mean, var

    def decode(self, z):
        """
        Decoder outputs reconstructed image in the following shapes:
        x_mean.shape = (batch_size, num_channels, width, height)
        """

        z = z.view(z.size(0), self.z_size, 1, 1)
        h = self.p_x_nn(z)
        x_mean = self.p_x_mean(h)

        return x_mean

    def forward(self, x):
        """
        Evaluates the model as a whole, encodes and decodes. Note that the log det jacobian is zero
         for a plain VAE (without flows), and z_0 = z_k.
        """

        # mean and variance of z
        z_mu, z_var = self.encode(x)
        # sample z
        z = self.reparameterize(z_mu, z_var)
        x_mean = self.decode(z)

        return x_mean, z_mu, z_var, self.log_det_j, z, z

from torch.nn.parameter import Parameter

class MaskedLinear(nn.Module):
    """
    Creates masked linear layer for MLP MADE.
    For input (x) to hidden (h) or hidden to hidden layers choose diagonal_zeros = False.
    For hidden to output (y) layers:
    If output depends on input through y_i = f(x_{<i}) set diagonal_zeros = True.
    Else if output depends on input through y_i = f(x_{<=i}) set diagonal_zeros = False.
    """

    def __init__(self, in_features, out_features, diagonal_zeros=False, bias=True):
        super(MaskedLinear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.diagonal_zeros = diagonal_zeros
        self.weight = Parameter(torch.FloatTensor(in_features, out_features))
        if bias:
            self.bias = Parameter(torch.FloatTensor(out_features))
        else:
            self.register_parameter('bias', None)
        mask = torch.from_numpy(self.build_mask())
        if torch.cuda.is_available():
            mask = mask.cuda()
        self.mask = torch.autograd.Variable(mask, requires_grad=False)
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_normal_(self.weight)
        if self.bias is not None:
            self.bias.data.zero_()

    def build_mask(self):
        n_in, n_out = self.in_features, self.out_features
        assert n_in % n_out == 0 or n_out % n_in == 0

        mask = np.ones((n_in, n_out), dtype=np.float32)
        if n_out >= n_in:
            k = n_out // n_in
            for i in range(n_in):
                mask[i + 1:, i * k:(i + 1) * k] = 0
                if self.diagonal_zeros:
                    mask[i:i + 1, i * k:(i + 1) * k] = 0
        else:
            k = n_in // n_out
            for i in range(n_out):
                mask[(i + 1) * k:, i:i + 1] = 0
                if self.diagonal_zeros:
                    mask[i * k:(i + 1) * k:, i:i + 1] = 0
        return mask

    def forward(self, x):
        output = x.mm(self.mask * self.weight)

        if self.bias is not None:
            return output.add(self.bias.expand_as(output))
        else:
            return output

    def __repr__(self):
        if self.bias is not None:
            bias = True
        else:
            bias = False
        return self.__class__.__name__ + ' (' \
            + str(self.in_features) + ' -> ' \
            + str(self.out_features) + ', diagonal_zeros=' \
            + str(self.diagonal_zeros) + ', bias=' \
            + str(bias) + ')'


class MaskedConv2d(nn.Module):
    """
    Creates masked convolutional autoregressive layer for pixelCNN.
    For input (x) to hidden (h) or hidden to hidden layers choose diagonal_zeros = False.
    For hidden to output (y) layers:
    If output depends on input through y_i = f(x_{<i}) set diagonal_zeros = True.
    Else if output depends on input through y_i = f(x_{<=i}) set diagonal_zeros = False.
    """

    def __init__(self, in_features, out_features, size_kernel=(3, 3), diagonal_zeros=False, bias=True):
        super(MaskedConv2d, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.size_kernel = size_kernel
        self.diagonal_zeros = diagonal_zeros
        self.weight = Parameter(torch.FloatTensor(out_features, in_features, *self.size_kernel))
        if bias:
            self.bias = Parameter(torch.FloatTensor(out_features))
        else:
            self.register_parameter('bias', None)
        mask = torch.from_numpy(self.build_mask())
        if torch.cuda.is_available():
            mask = mask.cuda()
        self.mask = torch.autograd.Variable(mask, requires_grad=False)
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_normal_(self.weight)
        if self.bias is not None:
            self.bias.data.zero_()

    def build_mask(self):
        n_in, n_out = self.in_features, self.out_features

        assert n_out % n_in == 0 or n_in % n_out == 0, "%d - %d" % (n_in, n_out)

        # Build autoregressive mask
        l = (self.size_kernel[0] - 1) // 2
        m = (self.size_kernel[1] - 1) // 2
        mask = np.ones((n_out, n_in, self.size_kernel[0], self.size_kernel[1]), dtype=np.float32)
        mask[:, :, :l, :] = 0
        mask[:, :, l, :m] = 0

        if n_out >= n_in:
            k = n_out // n_in
            for i in range(n_in):
                mask[i * k:(i + 1) * k, i + 1:, l, m] = 0
                if self.diagonal_zeros:
                    mask[i * k:(i + 1) * k, i:i + 1, l, m] = 0
        else:
            k = n_in // n_out
            for i in range(n_out):
                mask[i:i + 1, (i + 1) * k:, l, m] = 0
                if self.diagonal_zeros:
                    mask[i:i + 1, i * k:(i + 1) * k:, l, m] = 0

        return mask

    def forward(self, x):
        output = F.conv2d(x, self.mask * self.weight, bias=self.bias, padding=(1, 1))
        return output

    def __repr__(self):
        if self.bias is not None:
            bias = True
        else:
            bias = False
        return self.__class__.__name__ + ' (' \
            + str(self.in_features) + ' -> ' \
            + str(self.out_features) + ', diagonal_zeros=' \
            + str(self.diagonal_zeros) + ', bias=' \
            + str(bias) + ', size_kernel=' \
            + str(self.size_kernel) + ')'

class Sylvester(nn.Module):
    """
    Sylvester normalizing flow.
    """

    def __init__(self, num_ortho_vecs):

        super(Sylvester, self).__init__()

        self.num_ortho_vecs = num_ortho_vecs

        self.h = nn.Tanh()

        triu_mask = torch.triu(torch.ones(num_ortho_vecs, num_ortho_vecs), diagonal=1).unsqueeze(0)
        diag_idx = torch.arange(0, num_ortho_vecs).long()

        self.register_buffer('triu_mask', Variable(triu_mask))
        self.triu_mask.requires_grad = False
        self.register_buffer('diag_idx', diag_idx)

    def der_h(self, x):
        return self.der_tanh(x)

    def der_tanh(self, x):
        return 1 - self.h(x) ** 2

    def _forward(self, zk, r1, r2, q_ortho, b, sum_ldj=True):
        """
        All flow parameters are amortized. Conditions on diagonals of R1 and R2 for invertibility need to be satisfied
        outside of this function. Computes the following transformation:
        z' = z + QR1 h( R2Q^T z + b)
        or actually
        z'^T = z^T + h(z^T Q R2^T + b^T)R1^T Q^T
        :param zk: shape: (batch_size, z_size)
        :param r1: shape: (batch_size, num_ortho_vecs, num_ortho_vecs)
        :param r2: shape: (batch_size, num_ortho_vecs, num_ortho_vecs)
        :param q_ortho: shape (batch_size, z_size , num_ortho_vecs)
        :param b: shape: (batch_size, 1, self.z_size)
        :return: z, log_det_j
        """

        # Amortized flow parameters
        zk = zk.unsqueeze(1)

        # Save diagonals for log_det_j
        diag_r1 = r1[:, self.diag_idx, self.diag_idx]
        diag_r2 = r2[:, self.diag_idx, self.diag_idx]

        r1_hat = r1
        r2_hat = r2

        qr2 = torch.bmm(q_ortho, r2_hat.transpose(2, 1))
        qr1 = torch.bmm(q_ortho, r1_hat)

        r2qzb = torch.bmm(zk, qr2) + b
        z = torch.bmm(self.h(r2qzb), qr1.transpose(2, 1)) + zk
        z = z.squeeze(1)

        # Compute log|det J|
        # Output log_det_j in shape (batch_size) instead of (batch_size,1)
        diag_j = diag_r1 * diag_r2
        diag_j = self.der_h(r2qzb).squeeze(1) * diag_j
        diag_j += 1.
        log_diag_j = diag_j.abs().log()

        if sum_ldj:
            log_det_j = log_diag_j.sum(-1)
        else:
            log_det_j = log_diag_j

        return z, log_det_j

    def forward(self, zk, r1, r2, q_ortho, b, sum_ldj=True):

        return self._forward(zk, r1, r2, q_ortho, b, sum_ldj)

class OrthogonalSylvesterVAE(VAE):
    """
    Variational auto-encoder with orthogonal flows in the encoder.
    """

    def __init__(self, input_size, input_type, z_size, device, num_flows, num_ortho_vecs):
        super(OrthogonalSylvesterVAE, self).__init__(input_size, input_type, z_size, device)

        # Initialize log-det-jacobian to zero
        self.log_det_j = 0.

        # Flow parameters
        flow = Sylvester
        self.num_flows = num_flows
        self.num_ortho_vecs = num_ortho_vecs

        assert (self.num_ortho_vecs <= self.z_size) and (self.num_ortho_vecs > 0)

        # Orthogonalization parameters
        if self.num_ortho_vecs == self.z_size:
            self.cond = 1.e-5
        else:
            self.cond = 1.e-6

        self.steps = 100
        identity = torch.eye(self.num_ortho_vecs, self.num_ortho_vecs)
        # Add batch dimension
        identity = identity.unsqueeze(0)
        # Put identity in buffer so that it will be moved to GPU if needed by any call of .cuda
        self.register_buffer('_eye', Variable(identity))
        self._eye.requires_grad = False

        # Masks needed for triangular R1 and R2.
        triu_mask = torch.triu(torch.ones(self.num_ortho_vecs, self.num_ortho_vecs), diagonal=1)
        triu_mask = triu_mask.unsqueeze(0).unsqueeze(3)
        diag_idx = torch.arange(0, self.num_ortho_vecs).long()

        self.register_buffer('triu_mask', Variable(triu_mask))
        self.triu_mask.requires_grad = False
        self.register_buffer('diag_idx', diag_idx)

        # Amortized flow parameters
        # Diagonal elements of R1 * R2 have to satisfy -1 < R1 * R2 for flow to be invertible
        self.diag_activation = nn.Tanh()

        self.amor_d = nn.Linear(self.q_z_nn_output_dim, self.num_flows * self.num_ortho_vecs * self.num_ortho_vecs)

        self.amor_diag1 = nn.Sequential(
            nn.Linear(self.q_z_nn_output_dim, self.num_flows * self.num_ortho_vecs),
            self.diag_activation
        )
        self.amor_diag2 = nn.Sequential(
            nn.Linear(self.q_z_nn_output_dim, self.num_flows * self.num_ortho_vecs),
            self.diag_activation
        )

        self.amor_q = nn.Linear(self.q_z_nn_output_dim, self.num_flows * self.z_size * self.num_ortho_vecs)
        self.amor_b = nn.Linear(self.q_z_nn_output_dim, self.num_flows * self.num_ortho_vecs)

        # Normalizing flow layers
        for k in range(self.num_flows):
            flow_k = flow(self.num_ortho_vecs)
            self.add_module('flow_' + str(k), flow_k)

    def batch_construct_orthogonal(self, q):
        """
        Batch orthogonal matrix construction.
        :param q:  q contains batches of matrices, shape : (batch_size * num_flows, z_size * num_ortho_vecs)
        :return: batches of orthogonalized matrices, shape: (batch_size * num_flows, z_size, num_ortho_vecs)
        """

        # Reshape to shape (num_flows * batch_size, z_size * num_ortho_vecs)
        q = q.view(-1, self.z_size * self.num_ortho_vecs)

        norm = torch.norm(q, p=2, dim=1, keepdim=True)
        amat = torch.div(q, norm)
        dim0 = amat.size(0)
        amat = amat.resize(dim0, self.z_size, self.num_ortho_vecs)

        max_norm = 0.

        # Iterative orthogonalization
        for s in range(self.steps):
            tmp = torch.bmm(amat.transpose(2, 1), amat)
            tmp = self._eye - tmp
            tmp = self._eye + 0.5 * tmp
            amat = torch.bmm(amat, tmp)

            # Testing for convergence
            test = torch.bmm(amat.transpose(2, 1), amat) - self._eye
            norms2 = torch.sum(torch.norm(test, p=2, dim=2) ** 2, dim=1)
            norms = torch.sqrt(norms2)
            max_norm = torch.max(norms).item()
            if max_norm <= self.cond:
                break

        if max_norm > self.cond:
            print('\nWARNING WARNING WARNING: orthogonalization not complete')
            print('\t Final max norm =', max_norm)

            print()

        # Reshaping: first dimension is batch_size
        amat = amat.view(-1, self.num_flows, self.z_size, self.num_ortho_vecs)
        amat = amat.transpose(0, 1)

        return amat

    def encode(self, x):
        """
        Encoder that ouputs parameters for base distribution of z and flow parameters.
        """

        batch_size = x.size(0)

        h = self.q_z_nn(x)
        h = h.view(-1, self.q_z_nn_output_dim)
        mean_z = self.q_z_mean(h)
        var_z = self.q_z_var(h)

        # Amortized r1, r2, q, b for all flows

        full_d = self.amor_d(h)
        diag1 = self.amor_diag1(h)
        diag2 = self.amor_diag2(h)

        full_d = full_d.resize(batch_size, self.num_ortho_vecs, self.num_ortho_vecs, self.num_flows)
        diag1 = diag1.resize(batch_size, self.num_ortho_vecs, self.num_flows)
        diag2 = diag2.resize(batch_size, self.num_ortho_vecs, self.num_flows)

        r1 = full_d * self.triu_mask
        r2 = full_d.transpose(2, 1) * self.triu_mask

        r1[:, self.diag_idx, self.diag_idx, :] = diag1
        r2[:, self.diag_idx, self.diag_idx, :] = diag2

        q = self.amor_q(h)
        b = self.amor_b(h)

        # Resize flow parameters to divide over K flows
        b = b.resize(batch_size, 1, self.num_ortho_vecs, self.num_flows)

        return mean_z, var_z, r1, r2, q, b

    def forward(self, x):
        """
        Forward pass with orthogonal sylvester flows for the transformation z_0 -> z_1 -> ... -> z_k.
        Log determinant is computed as log_det_j = N E_q_z0[\sum_k log |det dz_k/dz_k-1| ].
        """

        self.log_det_j = 0.

        z_mu, z_var, r1, r2, q, b = self.encode(x)

        # Orthogonalize all q matrices
        q_ortho = self.batch_construct_orthogonal(q)

        # Sample z_0
        z = [self.reparameterize(z_mu, z_var)]

        # Normalizing flows
        for k in range(self.num_flows):

            flow_k = getattr(self, 'flow_' + str(k))
            z_k, log_det_jacobian = flow_k(z[k], r1[:, :, :, k], r2[:, :, :, k], q_ortho[k, :, :, :], b[:, :, :, k])

            z.append(z_k)
            self.log_det_j += log_det_jacobian

        x_mean = self.decode(z[-1])

        return x_mean, z_mu, z_var, self.log_det_j, z[0], z[-1]

import math

MIN_EPSILON = 1e-5
MAX_EPSILON = 1.-1e-5

PI = Variable(torch.FloatTensor([math.pi]))
PI.requires_grad = False
if torch.cuda.is_available():
    PI = PI.cuda()

# N(x | mu, var) = 1/sqrt{2pi var} exp[-1/(2 var) (x-mean)(x-mean)]
# log N(x| mu, var) = -log sqrt(2pi) -0.5 log var - 0.5 (x-mean)(x-mean)/var


def log_normal_diag(x, mean, log_var, average=False, reduce=True, dim=None):
    log_norm = -0.5 * (log_var + (x - mean) * (x - mean) * log_var.exp().reciprocal())
    if reduce:
        if average:
            return torch.mean(log_norm, dim)
        else:
            return torch.sum(log_norm, dim)
    else:
        return log_norm


def log_normal_normalized(x, mean, log_var, average=False, reduce=True, dim=None):
    log_norm = -(x - mean) * (x - mean)
    log_norm *= torch.reciprocal(2.*log_var.exp())
    log_norm += -0.5 * log_var
    log_norm += -0.5 * torch.log(2. * PI)

    if reduce:
        if average:
            return torch.mean(log_norm, dim)
        else:
            return torch.sum(log_norm, dim)
    else:
        return log_norm


def log_normal_standard(x, average=False, reduce=True, dim=None):
    log_norm = -0.5 * x * x

    if reduce:
        if average:
            return torch.mean(log_norm, dim)
        else:
            return torch.sum(log_norm, dim)
    else:
        return log_norm


def log_bernoulli(x, mean, average=False, reduce=True, dim=None):
    probs = torch.clamp(mean, min=MIN_EPSILON, max=MAX_EPSILON)
    log_bern = x * torch.log(probs) + (1. - x) * torch.log(1. - probs)
    if reduce:
        if average:
            return torch.mean(log_bern, dim)
        else:
            return torch.sum(log_bern, dim)
    else:
        return log_bern

class DCGANDiscriminator(nn.Module):
    def __init__(self, image_channels=1, height=32, length=32, hidden_size=64, blocks=4):
        super(DCGANDiscriminator, self).__init__()
        self.hidden_size = hidden_size
        self.blocks = blocks

        self.initial_conv = nn.Conv2d(image_channels, hidden_size, (5, 5), padding=(2, 2))
        self.initial_norm = nn.LayerNorm([hidden_size, height, length])
        self.initial_activ = nn.PReLU(hidden_size)

        self.convs = nn.ModuleList(
            [nn.Conv2d(hidden_size * 2 ** i, hidden_size * 2 ** (i + 1), (5, 5), padding=(2, 2)) for
             i in range(blocks)])
        self.norm = nn.ModuleList([nn.LayerNorm(
            [hidden_size * 2 ** (i + 1), height // (2 ** i), length // (2 ** i)]) for i
                                   in range(blocks)])
        self.activ = nn.ModuleList([nn.PReLU(hidden_size * 2 ** (i + 1)) for i in range(blocks)])

        self.final_linear = nn.Linear(1024, 1)

    def forward(self, inputs):
        x = self.initial_conv(inputs)
        x = self.initial_norm(x)
        x = self.initial_activ(x)

        for i in range(self.blocks):
            x = self.convs[i](x)
            x = self.norm[i](x)
            x = self.activ[i](x)
            x = F.avg_pool2d(x, kernel_size=(2, 2))

        x = x.view(x.shape[0], -1)
        x = self.final_linear(x)
        return x

import torch
import torch.optim as optim
import torch.autograd as autograd

from tensorboardX import SummaryWriter
import numpy as np
import os

import torch.nn.functional as F
import matplotlib.pyplot as plt

warmup = 100
max_beta = 1.

def wassertein_loss(inputs, targets):
    return torch.mean(inputs * targets)


def calc_gradient_penalty(discriminator, real_batch, fake_batch):
    epsilon = torch.rand(real_batch.shape[0], 1, device=device)
    interpolates = epsilon.view(-1, 1, 1, 1) * real_batch + (1 - epsilon).view(-1, 1, 1, 1) * fake_batch
    interpolates = autograd.Variable(interpolates, requires_grad=True)
    disc_interpolates = discriminator(interpolates)

    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,
                              grad_outputs=torch.ones(disc_interpolates.size(), device=device),
                              create_graph=True, retain_graph=True, only_inputs=True)[0]

    # lambda = 10
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10
    return gradient_penalty

def normalize_data(data):
    data *= 2
    data -= 1
    return data

def unnormalize_data(data):
    data += 1
    data /= 2
    return data

class FIGR:
    def __init__(self):
        self.load_args()
        self.id_string = self.get_id_string()
        self.writer = SummaryWriter('logs/' + self.id_string)
        self.env = eval(self.dataset + 'MetaEnv(height=self.height, length=self.length)')
        self.initialize_vae()
        #self.load_checkpoint()
    
    def load_args(self):
        self.outer_learning_rate = 1e-3
        self.inner_learning_rate = 1e-4
        self.batch_size = 8
        self.inner_epochs = 10
        self.height = 28
        self.length = 28
        self.dataset = 'Mnist'
        self.network = 'OrthogonalSylvesterVAE'
        self.x_dim = self.height * self.length
        self.z_dim = 64
        self.h_dim = 128
        self.num_block = 4
        self.nlayers = 4
        self.lmbda = 0.0
        self.eps= 0
        self.device = device
        self.num_flows = 4
        self.num_ortho_vecs = 8
        if self.dataset == 'Mnist':
          self.input_size = [1, 28, 28]
          self.input_type = 'binary'
          self.channels = 1
    
    def get_id_string(self):
        return '{}_{}_olr{}_ilr{}_bsize{}_ie{}_h{}_l{}'.format(
            self.network,
            self.dataset,
            str(self.outer_learning_rate),
            str(self.inner_learning_rate),
            str(self.batch_size),
            str(self.inner_epochs),
            str(self.height),
            str(self.length)
        )
    
    def load_checkpoint(self):
        if os.path.isfile('logs/' + self.id_string + '/checkpoint'):
            checkpoint = torch.load('logs/' + self.id_string + '/checkpoint')
            self.netVAE.load_state_dict(checkpoint['convae'])
            self.d.load_state_dict(checkpoint['discriminator'])
            self.eps = checkpoint['episode']
        else:
            self.eps = 0
    
    def initialize_vae(self):
        # D and G on CPU since they never to a feed forward operation
        self.netVAE = eval(self.network + '(self.input_size, self.input_type, self.z_dim, device=\'cpu\', num_flows=self.num_flows, num_ortho_vecs=self.num_ortho_vecs)')
        self.meta_netVAE = eval(self.network + '(self.input_size, self.input_type, self.z_dim, self.device, num_flows=self.num_flows, num_ortho_vecs=self.num_ortho_vecs)').to(device)
        self.d = DCGANDiscriminator(self.channels, self.height, self.length)
        self.meta_d = DCGANDiscriminator(self.channels, self.height, self.length).to(device)

        self.netVAE_optim = optim.Adamax(params=self.netVAE.parameters(), lr=self.outer_learning_rate)
        self.meta_netVAE_optim = optim.Adamax(params=self.meta_netVAE.parameters(), lr=self.inner_learning_rate, eps=1.e-7)
        self.d_optim = optim.Adam(params=self.d.parameters(), lr=self.outer_learning_rate)
        self.meta_d_optim = optim.SGD(params=self.meta_d.parameters(), lr=self.inner_learning_rate)

        self.discriminator_targets = torch.tensor([1] * self.batch_size + [-1] * self.batch_size, dtype=torch.float, device=device).view(-1, 1)
        self.generator_targets = torch.tensor([1] * self.batch_size, dtype=torch.float, device=device).view(-1, 1)

    def reset_meta_model(self):
        self.meta_netVAE.train()
        self.meta_netVAE.load_state_dict(self.netVAE.state_dict())
        self.meta_d.train()
        self.meta_d.load_state_dict(self.d.state_dict())

    def vae_loss_fn(self, recon_x, x, z_mu, z_var, z_0, z_k, ldj, beta=1.):
        reconstruction_function = nn.BCELoss(reduction='sum')
        batch_size = x.size(0)

        # - N E_q0 [ ln p(x|z_k) ]
        bce = reconstruction_function(recon_x, x)

        # ln p(z_k) (not averaged)
        log_p_zk = log_normal_standard(z_k, dim=1)
        # ln q(z_0) (not averaged)
        log_q_z0 = log_normal_diag(z_0, mean=z_mu, log_var=z_var.log(), dim=1)
        # N E_q0 [ ln q(z_0) - ln p(z_k) ]
        summed_logs = torch.sum(log_q_z0 - log_p_zk)

        # sum over batches
        summed_ldj = torch.sum(ldj)

        # ldj = N E_q_z0[\sum_k log |det dz_k/dz_k-1| ]
        kl = (summed_logs - summed_ldj)
        loss = bce + beta * kl

        loss = loss / float(batch_size)
        bce = bce / float(batch_size)
        kl = kl / float(batch_size)

        return loss, bce, kl
    
    def inner_loop(self, real_batch):
        self.meta_netVAE.train()
        
        #### Train VAE ####
        recon_batch, mu, logvar, ldj, z0, zk = self.meta_netVAE(real_batch)
        #beta = min([(self.eps * 1.) / max([warmup, 1.]), max_beta])
        recon_loss, bce_loss, kl_loss = self.vae_loss_fn(recon_batch, real_batch, mu, logvar, z0, zk, ldj, beta=0.5)

        #self.meta_netVAE.eval()
        #with torch.no_grad():
        fake_batch = self.meta_netVAE.decode(torch.tensor(np.random.normal(size=(self.batch_size, self.z_dim)), dtype=torch.float, device=device))


        #### Train Discriminator ####
        training_batch = torch.cat([real_batch, fake_batch])

        gradient_penalty = calc_gradient_penalty(self.meta_d, real_batch, fake_batch)
        discriminator_pred = self.meta_d(training_batch)
        discriminator_loss = wassertein_loss(discriminator_pred, self.discriminator_targets)
        discriminator_loss += gradient_penalty

        self.meta_d_optim.zero_grad()
        discriminator_loss.backward()
        self.meta_d_optim.step()

        #### Train VAE decoder ####
        output = self.meta_d(self.meta_netVAE.decode(torch.tensor(np.random.normal(size=(self.batch_size, self.z_dim)), dtype=torch.float, device=device)))
        generator_loss = wassertein_loss(output, self.generator_targets)

        total_gen_loss = generator_loss + recon_loss

        self.meta_netVAE_optim.zero_grad()
        total_gen_loss.backward()
        self.meta_netVAE_optim.step()

        return discriminator_loss.item(), generator_loss.item(), recon_loss.item(), bce_loss.item(), kl_loss.item(), mu, logvar

    
    def meta_training_loop(self):
        data, task = self.env.sample_training_task(self.batch_size)
        real_batch = data.to(device)
        #real_batch = normalize_data(real_batch)

        vae_total_loss = 0
        discriminator_total_loss = 0

        for _ in range(self.inner_epochs):
            d_loss, g_loss, recon_loss, bce_loss, kl_loss, _, _ = self.inner_loop(real_batch)
            vae_total_loss += (g_loss + recon_loss)
            discriminator_total_loss += d_loss
        
        self.writer.add_scalar('Training_vae_loss', vae_total_loss, self.eps)
        self.writer.add_scalar('Training_discriminator_loss', discriminator_total_loss, self.eps)
         
         # Updating both autoencoder and flow
        for p, meta_p in zip(self.netVAE.parameters(), self.meta_netVAE.parameters()):
             diff = p - meta_p.cpu()
             p.grad = diff
        self.netVAE_optim.step()

        for p, meta_p in zip(self.d.parameters(), self.meta_d.parameters()):
            diff = p - meta_p.cpu()
            p.grad = diff
        self.d_optim.step()
    
    def validation_run(self):
        data, task = self.env.sample_validation_task(self.batch_size)
        training_images = data.cpu().numpy()
        training_images = np.concatenate([training_images[i] for i in range(self.batch_size)], axis=-1)
        real_batch = data.to(device)
        #real_batch = normalize_data(real_batch)

        vae_total_loss = 0
        discriminator_total_loss = 0

        for _ in range(self.inner_epochs):
            d_loss, g_loss, recon_loss, bce_loss, kl_loss, output_mean, output_std = self.inner_loop(real_batch)
            vae_total_loss += (g_loss + recon_loss)
            discriminator_total_loss += d_loss
        
        #### Sampling the z variable, src: https://github.com/Sandipan99/pytorch/blob/master/VAE.py
        self.meta_netVAE.eval()
        with torch.no_grad():
            img = self.meta_netVAE.decode(torch.tensor(np.random.normal(size=(self.batch_size * 3, self.z_dim)), dtype=torch.float, device=device))
        img = img.detach().cpu().numpy()
        img = np.concatenate([np.concatenate([img[i * 3 + j] for j in range(3)], axis=-2) for i in range(self.batch_size)], axis=-1)
        #img = unnormalize_data(img)
        #img = recon_batch.detach().cpu()
        #img = np.concatenate([img[i] for i in range(self.batch_size)], axis=-1)
        img = np.concatenate([training_images, img], axis=-2)
        self.writer.add_image('Validation_generated', img, self.eps)
        self.writer.add_scalar('Validation_vae_loss', vae_total_loss, self.eps)
        self.writer.add_scalar('Validation_discriminator_loss', discriminator_total_loss, self.eps)
        
        plt.imshow(img[0], cmap='Greys_r')
        plt.show()
        print("Episode: {:.2f}\tD Loss: {:.2f}\tG Loss: {:.2f}\tRecon Loss: {:.2f}\tBCE Loss: {:.2f}\tKL Loss: {:.2f}".format(self.eps, d_loss, g_loss, recon_loss, bce_loss, kl_loss))
            

    def training(self):
        while self.eps <= 1000000:
            self.reset_meta_model()
            self.meta_training_loop()

            # Validation run every 10000 training loop
            if self.eps % 1000 == 0:
                self.reset_meta_model()
                self.validation_run()
                self.checkpoint_model()
            self.eps += 1
    
    def checkpoint_model(self):
        checkpoint = {'convae': self.netVAE.state_dict(),
                      'discriminator': self.d.state_dict(),
                      'episode': self.eps}
        torch.save(checkpoint, 'logs/' + self.id_string + '/checkpoint')

if __name__ == '__main__':
    env = FIGR()
    env.training()

